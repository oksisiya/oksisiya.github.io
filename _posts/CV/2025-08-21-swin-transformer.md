---
title: "[Paper Review] Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"
date: 2025-08-21 15:56:00 +0900
categories: [CV, Multi Modal]
---

&nbsp;

<br>

## Architecture

<br>

### Swin Transformer Block

<br>

### Shifted Window based Self-Attention

<br>

### Efficient Batch Computation for Shifted Configuration

<br>

![Efficient batch computation approach](/assets/img/2025-08-21/efficient-batch-computation-approach.png)

<Br>

### Relative Position Bias

<br>

### Architecture Variants

<br>

기본 모델(Swin-B)의 크기와 계산 복잡도를 변형시킨 3가지 모델들을 추가로 소개하고 있다.

<br>

||Swin-T(iny)|Swin-S(mall)|Swin-B(ase)|Swin-L(arge)|
|Size and <br>Computational Complexity|0.25×<br>(Similar to ResNet-50)|0.5×<br>(Similar to ResNet-101)|-|2×|

<br>



<br>

---
