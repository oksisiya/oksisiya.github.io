---
title: "Computer Vision Summary"
date: 2025-07-07 16:57:00 +0900
categories: CV
---

&nbsp;

## 2D Computer Vision

<br>

---

<br>

## 3D Computer Vision

<br>

* [ ] SuperPoint: Self-Supervised Interest Point Detection and Description
<br> (<https://arxiv.org/abs/1712.07629>)

<br>

* [ ] DISK: Learning local features with policy gradient
<br> (<https://arxiv.org/abs/2006.13566>)

<br>

---

<br>

## Multi-Modal

<br>

|Year|Model|Modality|Structure|
||---|---||
||BERT|Text||
||GPT|Text||
||ViT|Image||
|26 Feb 2021|**CLIP**|Text + Image|Text Encoder: Tokenizer(GPT like), transformer <br> Image Encoder: ViT|
|17 Aug 2021|SwinT|||
|19 Jul 2024|**Grounding DINO**|Text + Image|Text Encoder: BERT <br> Image Encoder: SwinT|
||BLIP|||
||BLIP-2|||
||Flamingo|||
||LLaVA|||

<br>

### Transformer Model for Language

<br>

* [ ] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
<br> (<https://arxiv.org/abs/1810.04805?source=post_page>)

<br>

* [ ] Improving Language Understanding by Generative Pre-Training
<br> (<https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf>)

<br>

### Transformer Model for Vision

<br>

* [ ] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale
<br> (<https://arxiv.org/abs/2010.11929>)

<br>

### Multi Modal Model

<br>

* [ ] Learning Transferable Visual Models From Natural Language Supervision
<br> (<https://arxiv.org/abs/2103.00020>)

<br>

* [ ] LAION-5B: An open large-scale dataset for training next generation image-text models
<br> (<https://arxiv.org/abs/2210.08402>)

<br>

* [ ] End-to-End Object Detection with Transformers
<br> (<https://arxiv.org/abs/2005.12872>)

<br>

* [ ] DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection
<br> (<https://arxiv.org/abs/2203.03605>)

<br>

* [ ] Swin Transformer: Hierarchical Vision Transformer using Shifted Windows
<br> (<https://arxiv.org/abs/2103.14030>)

<br>

* [ ] Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection
<br> (<https://arxiv.org/abs/2303.05499>)

<br>

### Vision Language Model

<br>

* [ ] BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation
<br> (<https://arxiv.org/abs/2201.12086>)

<br>

* [ ] BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models
<br> (<https://arxiv.org/abs/2301.12597>)

<br>

* [ ] Flamingo: a Visual Language Model for Few-Shot Learning
<br> (<https://arxiv.org/abs/2204.14198>)

<br>

* [ ] Visual Instruction Tuning
<br> (<https://arxiv.org/abs/2304.08485>)

<br>

### Vision Language Action Model

<br>

---

<br>

---
